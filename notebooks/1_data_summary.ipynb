{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary\n",
    "#### John R. Starr; jrs294@pitt.edu\n",
    "\n",
    "The data is split into two folders/files, en/TEP.xml and fa/TEP.xml. Let's import what we need to properly search through this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that we're in the correct directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\16starjo\\\\Documents\\\\Data_Science\\\\Scrambling-in-English-to-Persian-Subtitles'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to build a parser works for xml. I found documentation on etree.XMLParser() [here](https://lxml.de/api/lxml.etree.XMLParser-class.html). After some preliminary efforts in building trees, I found that some of my data has corrupted characters (or at least something along those lines). An example of one of these encoding errors can be found in the following sentence: <s id=\"86377\">simple caf oronary . freak show choked to death .</s> When opened in Notepad++, the space between \"caf\" and \"oronary\" is the abbreviation NUL highlighted in black. Other problems occur later in the dataset.\n",
    "\n",
    "In order to get my parser to work, I've hand-modified the dataset. Any modifications that I made can be found in the data_modifications.txt file [here](https://github.com/Data-Science-for-Linguists-2019/Scrambling-in-English-to-Persian-Subtitles/blob/master/data_modifications.txt). The name of this edited file is 'TEP_mod.xml' and will be used for the remainder of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new parser\n",
    "parser_full = etree.XMLParser(recover = True)\n",
    "tree_eng = ET.parse('Private/TEP/raw/en/TEP_mod.xml', parser = parser_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the root and see how our data is structured. I've looked through the XML file and noticed that there is a bit of a heading that looks like this (I have added spaces between the greater/less than symbols so that it remains visible in this file):\n",
    "\n",
    "< ?xml version=\"1.0\" encoding=\"utf-8\"? >\n",
    "< letsmt version=\"1.0\" >\n",
    "< head >< /head >\n",
    "    \n",
    "After that, we have the body character, followed by a sentence. So, we'll use .findall() to start where we want it to start, and hopefully we'll be able to get an idea of what our data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raspy breathing .\n",
      "['1']\n",
      "[('id', '1')]\n",
      "dad .\n",
      "['2']\n",
      "[('id', '2')]\n",
      "maybe its the wind .\n",
      "['3']\n",
      "[('id', '3')]\n",
      "no .\n",
      "['4']\n",
      "[('id', '4')]\n",
      "stop please stop .\n",
      "['5']\n",
      "[('id', '5')]\n"
     ]
    }
   ],
   "source": [
    "root_eng = tree_eng.getroot()\n",
    "root_eng.items()\n",
    "for item in root_eng.findall('./body/s')[:5]:\n",
    "    print(item.text)\n",
    "    #print(dir(item))\n",
    "    print(item.values())\n",
    "    print(item.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our data uses the ID number to mark what text comes after it. This works well, as we'll be able to match up the keys between the two files to combine them! Let's create a test dictionary in which the key is the item and the text is the value, replacing all extraneous information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines_test = {}\n",
    "for item in root_eng.findall('./body/s')[:5]:\n",
    "     eng_lines_test[int(str(item.values()).replace(',', '').replace(\"['\", '').replace(\"']\", ''))] = str(item.text.replace(',', '').replace(' .', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_lines_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['raspy breathing', 'dad', 'maybe its the wind', 'no', 'stop please stop'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_lines_test.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Let's do the same for the Farsi text as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_far = ET.parse('Private/TEP/raw/fa/TEP.xml', parser = parser_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "far_lines_test = {}\n",
    "root_far = tree_far.getroot()\n",
    "for item in root_far.findall('./body/s')[:5]:\n",
    "    far_lines_test[int(str(item.values()).replace(',', '').replace(\"['\", '').replace(\"']\", ''))] = str(item.text.replace(',', '').replace(' .', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_lines_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['صداي خر خر', 'پدر', 'شايد صداي باد باشه', 'نه', 'دست نگه داريد خواهش ميکنم دست نگه داريد'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_lines_test.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in the clear! Now, let's combine the two into a single DataFrame object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>far</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raspy breathing</td>\n",
       "      <td>صداي خر خر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dad</td>\n",
       "      <td>پدر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maybe its the wind</td>\n",
       "      <td>شايد صداي باد باشه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>نه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stop please stop</td>\n",
       "      <td>دست نگه داريد خواهش ميکنم دست نگه داريد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  eng                                      far\n",
       "1     raspy breathing                               صداي خر خر\n",
       "2                 dad                                      پدر\n",
       "3  maybe its the wind                       شايد صداي باد باشه\n",
       "4                  no                                       نه\n",
       "5    stop please stop  دست نگه داريد خواهش ميکنم دست نگه داريد"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_DF = pd.Series(eng_lines_test).to_frame('eng').join(pd.Series(far_lines_test).to_frame('far'), how='outer')\n",
    "test_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Yay! Let's apply this methodology for both of the files in full, rather than the little pieces we've been testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612086\n"
     ]
    }
   ],
   "source": [
    "eng_lines = {}\n",
    "for item in root_eng.findall('./body/s'):\n",
    "     eng_lines[int(str(item.values()).replace(',', '').replace(\"['\", '').replace(\"']\", ''))] = str(item.text.replace(',', '').replace(' .', ''))\n",
    "print(len(eng_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612086\n"
     ]
    }
   ],
   "source": [
    "far_lines = {}\n",
    "for item in root_far.findall('./body/s'):\n",
    "     far_lines[int(str(item.values()).replace(',', '').replace(\"['\", '').replace(\"']\", ''))] = str(item.text.replace(',', '').replace(' .', ''))\n",
    "print(len(far_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We have the same numbers. Let's see what the DF would look like, and then add some more information that might be useful to use in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Far</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raspy breathing</td>\n",
       "      <td>صداي خر خر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dad</td>\n",
       "      <td>پدر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maybe its the wind</td>\n",
       "      <td>شايد صداي باد باشه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>نه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stop please stop</td>\n",
       "      <td>دست نگه داريد خواهش ميکنم دست نگه داريد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>you have a week  evans then well burn the house</td>\n",
       "      <td>اوانز تو فقط يک هفته وقت داري وگرنه خونتو خواه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>william</td>\n",
       "      <td>ويليام</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>god damn it  william</td>\n",
       "      <td>لعنتي ويليام 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>god damn it put that down</td>\n",
       "      <td>لعنت به تو اونو بذار زمين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>let go</td>\n",
       "      <td>بذار برم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>its the last feed weve got</td>\n",
       "      <td>اين آخرين علوفه اي بود که ما داشتيم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ill take care of this</td>\n",
       "      <td>من خودم اين کارو انجام ميدهم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>no  you wont</td>\n",
       "      <td>نه تو نميکني</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>herds over the ridge by now you go get cleaned up</td>\n",
       "      <td>گله را آوردم بيرون الان تو برو اونجا را تميز کن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>you lied to me  dan</td>\n",
       "      <td>تو به من دروغ گفتي دن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>you told me we made payments to hollander we did</td>\n",
       "      <td>تو به من گفتي قرضمونو به هلندر پرداخت کرديم ما...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>so  how do you think we bought feed  alice thr...</td>\n",
       "      <td>خب پس تو فکر ميکني ما چطوري علوفه خريديم سه ما...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i had a choice between our family and paying t...</td>\n",
       "      <td>من فقط يک انتخاب بين خانوادم و پرداخت قرض اونا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>were supposed to make decisions together</td>\n",
       "      <td>ما قرار بود تصميماتو با هم بگيريم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>would you have made anything different</td>\n",
       "      <td>مگه تو تصميمه ديگه اي ميگرفتي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>alice  we cant make it rain together turn the ...</td>\n",
       "      <td>آليس مادوباره ميتونيم همه چي را دوباره جمع کني...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>we cant stop hollander from selling our land t...</td>\n",
       "      <td>ما هم نميتونيم جلوي هلندر را از فروش زمينمون ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>its too bad the doctors at the aid station did...</td>\n",
       "      <td>مشکل اينجاست که دکترها در درمانگاه کار زيادي ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stop looking at me like that</td>\n",
       "      <td>اينجوري به من نگاه نکن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>are you going to tell the marshal what those m...</td>\n",
       "      <td>تو ميخواي به مارشال بگي که اون آدما چيکار کردن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>marshal aint doing shit william</td>\n",
       "      <td>مارشال هيچ کاري واسمون نميکنه ويليام</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>first thing  mark im going to take you boys we...</td>\n",
       "      <td>مارک اول اينکه من ميخوام شما پسرهارو با خودم ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>what are you going to do there</td>\n",
       "      <td>تو ميخواي اونجا چيکار کني</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>im going to tell hollander to make this right</td>\n",
       "      <td>من به هلندر ميگم که اينو درستش کنه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>im going to tell him to pay for a new barn</td>\n",
       "      <td>من بهش ميگم پول يک اسطبل جديدو بده</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612057</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>کج و معوج</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612058</th>\n",
       "      <td>zinc</td>\n",
       "      <td>فلز روي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612059</th>\n",
       "      <td>zinc</td>\n",
       "      <td>قطب پيل ولتا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612060</th>\n",
       "      <td>zinc oxid</td>\n",
       "      <td>اکسيد دو زنگ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612061</th>\n",
       "      <td>zincky</td>\n",
       "      <td>بشکل روي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612062</th>\n",
       "      <td>zincography</td>\n",
       "      <td>قلمزني روي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612063</th>\n",
       "      <td>zincoid</td>\n",
       "      <td>شبيه فلز روي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612064</th>\n",
       "      <td>zincoid</td>\n",
       "      <td>روئين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612065</th>\n",
       "      <td>zing</td>\n",
       "      <td>صدائي شبيه جيغ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612066</th>\n",
       "      <td>zing</td>\n",
       "      <td>جيغ شديد و تند</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612067</th>\n",
       "      <td>zion</td>\n",
       "      <td>قوم اسرائيل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612068</th>\n",
       "      <td>zionism</td>\n",
       "      <td>صهيون گرائي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612069</th>\n",
       "      <td>zionism</td>\n",
       "      <td>نهضت صهيونيسم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612070</th>\n",
       "      <td>zionist</td>\n",
       "      <td>صهيون گرا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612071</th>\n",
       "      <td>zionist</td>\n",
       "      <td>صهيونيست</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612072</th>\n",
       "      <td>zip</td>\n",
       "      <td>نيروفشار</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612073</th>\n",
       "      <td>zip</td>\n",
       "      <td>زيپ دار کردن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612074</th>\n",
       "      <td>zip code</td>\n",
       "      <td>رمز منطقه پستي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612075</th>\n",
       "      <td>zipper</td>\n",
       "      <td>زيب لباس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612076</th>\n",
       "      <td>zipper</td>\n",
       "      <td>زيب دار</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612077</th>\n",
       "      <td>zippy</td>\n",
       "      <td>پر از وزوز</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612078</th>\n",
       "      <td>zippy</td>\n",
       "      <td>طر سروصدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612079</th>\n",
       "      <td>zippy</td>\n",
       "      <td>پر نيرو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612080</th>\n",
       "      <td>zodiac</td>\n",
       "      <td>زودياک</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612081</th>\n",
       "      <td>zodiac</td>\n",
       "      <td>منطقه‌البروج</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612082</th>\n",
       "      <td>zodiac</td>\n",
       "      <td>دايره‌البروج</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612083</th>\n",
       "      <td>zodiacal light</td>\n",
       "      <td>حمره مغربيه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612084</th>\n",
       "      <td>zombi</td>\n",
       "      <td>انسان زنده شد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612085</th>\n",
       "      <td>zombiism</td>\n",
       "      <td>مارخداگرائي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612086</th>\n",
       "      <td>zonal</td>\n",
       "      <td>مداري</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612086 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Eng  \\\n",
       "ID                                                          \n",
       "1                                         raspy breathing   \n",
       "2                                                     dad   \n",
       "3                                      maybe its the wind   \n",
       "4                                                      no   \n",
       "5                                        stop please stop   \n",
       "6         you have a week  evans then well burn the house   \n",
       "7                                                 william   \n",
       "8                                    god damn it  william   \n",
       "9                               god damn it put that down   \n",
       "10                                                 let go   \n",
       "11                             its the last feed weve got   \n",
       "12                                  ill take care of this   \n",
       "13                                           no  you wont   \n",
       "14      herds over the ridge by now you go get cleaned up   \n",
       "15                                    you lied to me  dan   \n",
       "16       you told me we made payments to hollander we did   \n",
       "17      so  how do you think we bought feed  alice thr...   \n",
       "18      i had a choice between our family and paying t...   \n",
       "19               were supposed to make decisions together   \n",
       "20                 would you have made anything different   \n",
       "21      alice  we cant make it rain together turn the ...   \n",
       "22      we cant stop hollander from selling our land t...   \n",
       "23      its too bad the doctors at the aid station did...   \n",
       "24                           stop looking at me like that   \n",
       "25      are you going to tell the marshal what those m...   \n",
       "26                        marshal aint doing shit william   \n",
       "27      first thing  mark im going to take you boys we...   \n",
       "28                         what are you going to do there   \n",
       "29          im going to tell hollander to make this right   \n",
       "30             im going to tell him to pay for a new barn   \n",
       "...                                                   ...   \n",
       "612057                                             zigzag   \n",
       "612058                                               zinc   \n",
       "612059                                               zinc   \n",
       "612060                                          zinc oxid   \n",
       "612061                                             zincky   \n",
       "612062                                        zincography   \n",
       "612063                                            zincoid   \n",
       "612064                                            zincoid   \n",
       "612065                                               zing   \n",
       "612066                                               zing   \n",
       "612067                                               zion   \n",
       "612068                                            zionism   \n",
       "612069                                            zionism   \n",
       "612070                                            zionist   \n",
       "612071                                            zionist   \n",
       "612072                                                zip   \n",
       "612073                                                zip   \n",
       "612074                                           zip code   \n",
       "612075                                             zipper   \n",
       "612076                                             zipper   \n",
       "612077                                              zippy   \n",
       "612078                                              zippy   \n",
       "612079                                              zippy   \n",
       "612080                                             zodiac   \n",
       "612081                                             zodiac   \n",
       "612082                                             zodiac   \n",
       "612083                                     zodiacal light   \n",
       "612084                                              zombi   \n",
       "612085                                           zombiism   \n",
       "612086                                              zonal   \n",
       "\n",
       "                                                      Far  \n",
       "ID                                                         \n",
       "1                                              صداي خر خر  \n",
       "2                                                     پدر  \n",
       "3                                      شايد صداي باد باشه  \n",
       "4                                                      نه  \n",
       "5                 دست نگه داريد خواهش ميکنم دست نگه داريد  \n",
       "6       اوانز تو فقط يک هفته وقت داري وگرنه خونتو خواه...  \n",
       "7                                                  ويليام  \n",
       "8                                          لعنتي ويليام 8  \n",
       "9                               لعنت به تو اونو بذار زمين  \n",
       "10                                               بذار برم  \n",
       "11                    اين آخرين علوفه اي بود که ما داشتيم  \n",
       "12                           من خودم اين کارو انجام ميدهم  \n",
       "13                                           نه تو نميکني  \n",
       "14        گله را آوردم بيرون الان تو برو اونجا را تميز کن  \n",
       "15                                  تو به من دروغ گفتي دن  \n",
       "16      تو به من گفتي قرضمونو به هلندر پرداخت کرديم ما...  \n",
       "17      خب پس تو فکر ميکني ما چطوري علوفه خريديم سه ما...  \n",
       "18      من فقط يک انتخاب بين خانوادم و پرداخت قرض اونا...  \n",
       "19                      ما قرار بود تصميماتو با هم بگيريم  \n",
       "20                          مگه تو تصميمه ديگه اي ميگرفتي  \n",
       "21      آليس مادوباره ميتونيم همه چي را دوباره جمع کني...  \n",
       "22      ما هم نميتونيم جلوي هلندر را از فروش زمينمون ب...  \n",
       "23      مشکل اينجاست که دکترها در درمانگاه کار زيادي ب...  \n",
       "24                                 اينجوري به من نگاه نکن  \n",
       "25         تو ميخواي به مارشال بگي که اون آدما چيکار کردن  \n",
       "26                   مارشال هيچ کاري واسمون نميکنه ويليام  \n",
       "27      مارک اول اينکه من ميخوام شما پسرهارو با خودم ب...  \n",
       "28                              تو ميخواي اونجا چيکار کني  \n",
       "29                     من به هلندر ميگم که اينو درستش کنه  \n",
       "30                     من بهش ميگم پول يک اسطبل جديدو بده  \n",
       "...                                                   ...  \n",
       "612057                                          کج و معوج  \n",
       "612058                                            فلز روي  \n",
       "612059                                       قطب پيل ولتا  \n",
       "612060                                       اکسيد دو زنگ  \n",
       "612061                                           بشکل روي  \n",
       "612062                                         قلمزني روي  \n",
       "612063                                       شبيه فلز روي  \n",
       "612064                                              روئين  \n",
       "612065                                     صدائي شبيه جيغ  \n",
       "612066                                     جيغ شديد و تند  \n",
       "612067                                        قوم اسرائيل  \n",
       "612068                                        صهيون گرائي  \n",
       "612069                                      نهضت صهيونيسم  \n",
       "612070                                          صهيون گرا  \n",
       "612071                                           صهيونيست  \n",
       "612072                                           نيروفشار  \n",
       "612073                                       زيپ دار کردن  \n",
       "612074                                     رمز منطقه پستي  \n",
       "612075                                           زيب لباس  \n",
       "612076                                            زيب دار  \n",
       "612077                                         پر از وزوز  \n",
       "612078                                          طر سروصدا  \n",
       "612079                                            پر نيرو  \n",
       "612080                                             زودياک  \n",
       "612081                                       منطقه‌البروج  \n",
       "612082                                       دايره‌البروج  \n",
       "612083                                        حمره مغربيه  \n",
       "612084                                      انسان زنده شد  \n",
       "612085                                        مارخداگرائي  \n",
       "612086                                              مداري  \n",
       "\n",
       "[612086 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.Series(eng_lines).to_frame('Eng').join(pd.Series(far_lines).to_frame('Far'), how='outer')\n",
    "full_df.index.name = 'ID'\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Far</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>612086</td>\n",
       "      <td>612086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>520291</td>\n",
       "      <td>583981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>yes.</td>\n",
       "      <td>بله</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1262</td>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Eng     Far\n",
       "count   612086  612086\n",
       "unique  520291  583981\n",
       "top       yes.     بله\n",
       "freq      1262    1596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting things to point out:\n",
    "- It appears that the subtitles include non-spoken acts of communication, such as \"raspy breathing\" or \"music playing\". I'm not entirely sure how to remove this data, as it is not marked in any particular way.\n",
    "- Also, poor William in the beginning! It seems that he's having a tough time...\n",
    "- \"Yes\" and it's Persian translation \"بله\" are the most common words, but they do not occur at the same frequency... This may be because it is common for Persian to repeat \"بله\" when speaking casually.\n",
    "\n",
    "Back to the data. Let's create three more columns for both langauges: token, token count (or length), and type. This will help us navigate the data when performing analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing Token columns\n",
    "full_df['Eng_Tok'] = full_df['Eng'].apply(nltk.word_tokenize)\n",
    "full_df['Far_Tok'] = full_df['Far'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing Len columns\n",
    "full_df['Eng_Len'] = full_df['Eng_Tok'].apply(len)\n",
    "full_df['Far_Len'] = full_df['Far_Tok'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing Type columns\n",
    "full_df['Eng_Types'] = full_df['Eng_Tok'].apply(set)\n",
    "full_df['Far_Types'] = full_df['Far_Tok'].apply(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing our resulting DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Far</th>\n",
       "      <th>Eng_Tok</th>\n",
       "      <th>Far_Tok</th>\n",
       "      <th>Eng_Len</th>\n",
       "      <th>Far_Len</th>\n",
       "      <th>Eng_Types</th>\n",
       "      <th>Far_Types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raspy breathing</td>\n",
       "      <td>صداي خر خر</td>\n",
       "      <td>[raspy, breathing]</td>\n",
       "      <td>[صداي, خر, خر]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{breathing, raspy}</td>\n",
       "      <td>{صداي, خر}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dad</td>\n",
       "      <td>پدر</td>\n",
       "      <td>[dad]</td>\n",
       "      <td>[پدر]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{dad}</td>\n",
       "      <td>{پدر}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maybe its the wind</td>\n",
       "      <td>شايد صداي باد باشه</td>\n",
       "      <td>[maybe, its, the, wind]</td>\n",
       "      <td>[شايد, صداي, باد, باشه]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>{wind, the, maybe, its}</td>\n",
       "      <td>{شايد, باشه, صداي, باد}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>نه</td>\n",
       "      <td>[no]</td>\n",
       "      <td>[نه]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{no}</td>\n",
       "      <td>{نه}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stop please stop</td>\n",
       "      <td>دست نگه داريد خواهش ميکنم دست نگه داريد</td>\n",
       "      <td>[stop, please, stop]</td>\n",
       "      <td>[دست, نگه, داريد, خواهش, ميکنم, دست, نگه, داريد]</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>{stop, please}</td>\n",
       "      <td>{نگه, دست, داريد, ميکنم, خواهش}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Eng                                      Far  \\\n",
       "ID                                                                \n",
       "1      raspy breathing                               صداي خر خر   \n",
       "2                  dad                                      پدر   \n",
       "3   maybe its the wind                       شايد صداي باد باشه   \n",
       "4                   no                                       نه   \n",
       "5     stop please stop  دست نگه داريد خواهش ميکنم دست نگه داريد   \n",
       "\n",
       "                    Eng_Tok                                           Far_Tok  \\\n",
       "ID                                                                              \n",
       "1        [raspy, breathing]                                    [صداي, خر, خر]   \n",
       "2                     [dad]                                             [پدر]   \n",
       "3   [maybe, its, the, wind]                           [شايد, صداي, باد, باشه]   \n",
       "4                      [no]                                              [نه]   \n",
       "5      [stop, please, stop]  [دست, نگه, داريد, خواهش, ميکنم, دست, نگه, داريد]   \n",
       "\n",
       "    Eng_Len  Far_Len                Eng_Types                        Far_Types  \n",
       "ID                                                                              \n",
       "1         2        3       {breathing, raspy}                       {صداي, خر}  \n",
       "2         1        1                    {dad}                            {پدر}  \n",
       "3         4        4  {wind, the, maybe, its}          {شايد, باشه, صداي, باد}  \n",
       "4         1        1                     {no}                             {نه}  \n",
       "5         3        8           {stop, please}  {نگه, دست, داريد, ميکنم, خواهش}  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many one-word lines are there? If a significant portion of my data consists of one-word lines, then it will be pretty challenging to get results analyzing the syntax of the subtitles. I'm going to predict that there will be more Persian one-word lines, as you don't need to include the subject in Persian and can simply utter a verb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59483\n",
      "35506\n",
      "35506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "612086"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing how many one-word lines there are in English, Farsi, and both.\n",
    "eng_1word = [x for x in full_df['Eng_Len'] if x == 1]\n",
    "print(len(eng_1word))\n",
    "\n",
    "far_1word = [x for x in full_df['Far_Len'] if x == 1]\n",
    "print(len(far_1word))\n",
    "\n",
    "both_1word = [x for x in full_df if len(full_df['Eng_Len']) == 1 if len(full_df['Far_Len']) == 1]\n",
    "print(len(far_1word))\n",
    "\n",
    "# Overall length of file:\n",
    "len(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! It looks like my hypothesis was wrong. Every Persian line that is one word is also one word in English. However, reverse is not true. This is something I will investigate further in my data analysis. \n",
    "\n",
    "These sentences do not take up a significant portion of my data, but I am considering removing them because they do not help me with my analysis. I will be meeting with one of the instructors to get a second opinion on this matter.\n",
    "\n",
    "Let's pickle the data as a whole and move it to my private folder, pickle a small portion of the data, get a little more information on the data, and then move on to POS tagging and shallow parsing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_pickle('full_df.pkl') # This will be put in my private folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 612086 entries, 1 to 612086\n",
      "Data columns (total 8 columns):\n",
      "Eng          612086 non-null object\n",
      "Far          612086 non-null object\n",
      "Eng_Tok      612086 non-null object\n",
      "Far_Tok      612086 non-null object\n",
      "Eng_Len      612086 non-null int64\n",
      "Far_Len      612086 non-null int64\n",
      "Eng_Types    612086 non-null object\n",
      "Far_Types    612086 non-null object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 62.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Seeing general information about the DF\n",
    "full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we don't have any null values! This is good (and expected). What's the average sentence length for each language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     60403\n",
       "1     59483\n",
       "7     58117\n",
       "5     57950\n",
       "8     54154\n",
       "4     52814\n",
       "9     47822\n",
       "10    40727\n",
       "3     40255\n",
       "2     36142\n",
       "11    32389\n",
       "12    24742\n",
       "13    18157\n",
       "14    12105\n",
       "15     7419\n",
       "16     4401\n",
       "17     2397\n",
       "18     1293\n",
       "19      618\n",
       "20      312\n",
       "21      178\n",
       "22      100\n",
       "23       52\n",
       "24       16\n",
       "25       15\n",
       "26        9\n",
       "27        6\n",
       "28        5\n",
       "29        3\n",
       "31        1\n",
       "34        1\n",
       "Name: Eng_Len, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.Eng_Len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     67818\n",
       "5     60178\n",
       "6     60088\n",
       "4     56988\n",
       "3     55920\n",
       "7     55866\n",
       "8     49803\n",
       "9     42446\n",
       "1     35506\n",
       "10    34563\n",
       "11    27501\n",
       "12    20660\n",
       "13    15037\n",
       "14    10603\n",
       "15     7179\n",
       "16     4809\n",
       "17     2958\n",
       "18     1709\n",
       "19     1052\n",
       "20      641\n",
       "21      353\n",
       "22      174\n",
       "23       94\n",
       "24       51\n",
       "25       35\n",
       "26       25\n",
       "27        9\n",
       "28        6\n",
       "30        6\n",
       "29        5\n",
       "32        1\n",
       "31        1\n",
       "34        1\n",
       "Name: Far_Len, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.Far_Len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.738687047244995\n"
     ]
    }
   ],
   "source": [
    "# Average English sentence length\n",
    "eng_len_tot = []\n",
    "for item in full_df['Eng_Len']:\n",
    "    eng_len_tot.append(item)\n",
    "eng_len_avg = (sum(eng_len_tot))/len(full_df)\n",
    "print(eng_len_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.46187953980323\n"
     ]
    }
   ],
   "source": [
    "# Average Farsi sentence length\n",
    "far_len_tot = []\n",
    "for item in full_df['Far_Len']:\n",
    "    far_len_tot.append(item)\n",
    "far_len_avg = (sum(far_len_tot))/len(full_df)\n",
    "print(far_len_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the sentences are pretty comparable in average length. This conclusion can be inferred from looking at the overall value counts for each of the languages. \n",
    "\n",
    "I think that's it for data exploration and summarization. Let's move to tagging and parsing the data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
